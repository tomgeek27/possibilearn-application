{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OlivettiFaces.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wW8kE3vKFLHr",
        "O4C4WrkDG-Rq",
        "dk3YMY6UGHQ5"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VipYlGoFGbhD"
      },
      "source": [
        "# Initialization & setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "l18wx620eNiE"
      },
      "outputs": [],
      "source": [
        "#google colab\n",
        "!pip uninstall tensorflow; pip install tensorflow==2.0.0-beta1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "colab_type": "code",
        "id": "Kn9wlY41di6j",
        "outputId": "b7828e1a-63c7-4d98-efcc-d9b94d31febe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/tensorflow-1.15.0/python3.6',\n",
              " '',\n",
              " '/env/python',\n",
              " '/usr/lib/python36.zip',\n",
              " '/usr/lib/python3.6',\n",
              " '/usr/lib/python3.6/lib-dynload',\n",
              " '/usr/local/lib/python3.6/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/content/drive/My Drive/Tesi/',\n",
              " '/content/drive/My Drive/',\n",
              " '/content/drive/My Drive/fuzzylearn/',\n",
              " '/content/drive/My Drive/fuzzylearn/']"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#google colab\n",
        "import sys\n",
        "ROOT = '/content/drive/My Drive/'\n",
        "PROJ = 'Tesi/'\n",
        "LOG = PROJ + 'logs/file.log'\n",
        "PROJ_COMPLETE_PATH = ROOT + PROJ\n",
        "LOG_COMPELTE_PATH = ROOT + LOG\n",
        "\n",
        "if(PROJ_COMPLETE_PATH not in sys.path):\n",
        "  sys.path.append(PROJ_COMPLETE_PATH)\n",
        "\n",
        "if(ROOT not in sys.path):\n",
        "  sys.path.append(ROOT)\n",
        "\n",
        "sys.path.append(ROOT + 'fuzzylearn/')\n",
        "\n",
        "sys.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ELHiIEV64hSP"
      },
      "outputs": [],
      "source": [
        "#google colab\n",
        "\n",
        "###Â uncomment these line if there isn't already fuzzylearn repo in google drive\n",
        "#!rm -rf /content/drive/My\\ Drive/Tesi\n",
        "#!mkdir /content/drive/My\\ Drive/Tesi/\n",
        "#!git clone https://tomgeek27@bitbucket.org/tomgeek27/riconoscimento-volti-tesi.git /content/drive/My\\ Drive/Tesi/\n",
        "\n",
        "### uncomment this line if you need to update your repo (updated from develop branch)\n",
        "#!cd /content/drive/My\\ Drive/Tesi; git pull origin develop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QBDsd1exKXB7"
      },
      "source": [
        "# Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kS1BDH9hJdkB"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "def log_init(filename=\"/content/drive/My Drive/Tesi/logs/file2.log\"):\n",
        "\n",
        "  logger = logging.getLogger(__name__)\n",
        "  logger.setLevel(logging.INFO)\n",
        "  if(not logger.hasHandlers()):\n",
        "    f_handler = logging.FileHandler(filename)\n",
        "    f_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
        "\n",
        "    c_handler = logging.StreamHandler()\n",
        "    c_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
        "    logger.addHandler(f_handler)\n",
        "    logger.addHandler(c_handler)\n",
        "\n",
        "  return logger\n",
        "\n",
        "def log_info(logger, label, message, *args):\n",
        "  if(logger != None):\n",
        "    if(label == None):\n",
        "      logger.info(message, *args)\n",
        "    else:\n",
        "      logger.info(\"(\" + str(label) + \") - \" + message, *args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dv6cRFVSltHS"
      },
      "source": [
        "# Log parser\n",
        "\n",
        "Here you can find all tools that you need to retrieve information from _file.log_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "K7CmvdXBotJE"
      },
      "outputs": [],
      "source": [
        "def str2fuzzifier(f_str):\n",
        "  if(f_str == 'LinearFuzzifier'):\n",
        "    return fl.fuzzifiers.LinearFuzzifier\n",
        "  elif(f_str == 'QuantileLinearPiecewiseFuzzifier'):\n",
        "    return fl.fuzzifiers.QuantileLinearPiecewiseFuzzifier\n",
        "\n",
        "def str2kernel(k_str):\n",
        "  if(k_str == 'GaussianKernel'):\n",
        "    return fl.kernel.GaussianKernel\n",
        "\n",
        "def lastAnalyzedClass(lines):\n",
        "  \"\"\"Return the label of the last trained class, you could use it for train all model after the last trained\"\"\"\n",
        "  return list(bestParams(lines).keys())[-1]\n",
        "\n",
        "def bestParams(lines):\n",
        "  \"\"\"Return params produced best results\"\"\"\n",
        "  return _searchForValue(lines, \"BEST_PARAMS_\")\n",
        "\n",
        "def bestScores(lines):\n",
        "  \"\"\"Return best score for all model\"\"\"\n",
        "  return _searchForValue(lines, \"BEST_SCORE_\")\n",
        "\n",
        "def params(lines):\n",
        "  \"\"\"Return all params used for train all model\"\"\"\n",
        "  return _searchForValue(lines, \"Started GridSearchCV\")\n",
        "\n",
        "def params_nested(lines):\n",
        "  return _searchForValue(lines, \"Started Started Nested-GridSearchCV\")\n",
        "\n",
        "def getNestedResults(lines):\n",
        "  return _searchForValue(lines, \"NESTED CROSS VALIDATION with\")\n",
        "\n",
        "def getNestedMean(lines):\n",
        "  return _searchForValue(lines, \"NESTED CROSS VALIDATION (mean)\")\n",
        "\n",
        "def dataDimension(lines):\n",
        "  \"\"\"Return the number of feature used for training model\"\"\"\n",
        "  dataDimension_ = _searchForValue(lines, \"DATA_DIMENSION_\")\n",
        "  if(dataDimension_ == {}):\n",
        "    defaultMap = {}\n",
        "\n",
        "    for i in np.unique(olivetti_labels):\n",
        "      defaultMap[i] = 2\n",
        "    \n",
        "    return defaultMap\n",
        "\n",
        "  return dataDimension_\n",
        "\n",
        "def _searchForValue(lines, v):\n",
        "  m = {}\n",
        "  for x in lines:\n",
        "    if(v in x):\n",
        "      c = x[x.index('(') + 1: x.index(')')]\n",
        "      m[c] = x[x.index(': ') + 2:-2]\n",
        "  \n",
        "  return m\n",
        "\n",
        "def logLines(log):\n",
        "  f = open(log, \"r\")\n",
        "  return [x for x in f]\n",
        "\n",
        "def get_params(lines, label):\n",
        "  line = bestParams(lines)[label]\n",
        "\n",
        "  line_params = line.split(',')\n",
        "  c_ = int(line_params[0][line_params[0].index(': ') + 2:])\n",
        "  fuzzifier_ = line_params[1].split('.')[-1][:-2]\n",
        "\n",
        "  k_ = line_params[2][6:line_params[2].index('(')]\n",
        "  param_k_ = float(line_params[2][line_params[2].index('(')+1:line_params[2].index(')')])\n",
        "  return (c_, fuzzifier_, (k_, param_k_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yIcorIegGn8D"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VyDNbGniVkTM"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "olivetti = fetch_olivetti_faces()\n",
        "\n",
        "olivetti_data = olivetti.data\n",
        "olivetti_labels = olivetti.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DukjEGj-gi6Z"
      },
      "outputs": [],
      "source": [
        "def get_classes(dataset_labels):\n",
        "  return np.unique(dataset_labels)\n",
        "\n",
        "def get_tsne_data(dataset, dimension=2):\n",
        "  return TSNE(n_components=dimension).fit_transform(dataset) if dimension < 4 else TSNE(n_components=dimension).fit_transform(dataset)\n",
        "\n",
        "def get_pca_data(dataset, dimension=2):\n",
        "  pca_xd = PCA(n_components=dimension)\n",
        "  data_xd = pca_xd.fit_transform(dataset) \n",
        "  return data_xd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "3lUUVMJfXRSW",
        "outputId": "e73cffef-d489-4965-c727-09c9672d9d26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gurobi not available\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedShuffleSplit\n",
        "import fuzzylearn as fl\n",
        "import logging\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import importlib\n",
        "\n",
        "importlib.reload(fl)\n",
        "def estimate_membership_holdout(x, y, c=1, k=fl.kernel.GaussianKernel(sigma=.5), fuzzifier=fl.fuzzifiers.LinearFuzzifier, y_needs_mapping=False, label=\"\"):\n",
        "  if(y_needs_mapping):\n",
        "    y = map_labels(y, label)\n",
        "  model = fl.FuzzyInductor(c=c, k=k, fuzzifier=fuzzifier).fit(x, y)\n",
        "\n",
        "  return model\n",
        "\n",
        "def grid_search(x, y, params, data_dimension, data_reduction=\"t\", logger=None, y_needs_mapping=False, label=\"\", folds=3):\n",
        "  \"\"\"data_reduction: use \"t\" for refer to t-SNE, use \"p\" to refer to PCA\"\"\"\n",
        "  check_label(label)\n",
        "  \n",
        "  if(y_needs_mapping):\n",
        "    y = map_labels(y, label)\n",
        "\n",
        "  log_info(logger, label, \"Started GridSearchCV with: %s\", params)\n",
        "  log_info(logger, label, \"DATA_REDUCTION_: %s\", data_reduction)\n",
        "  log_info(logger, label, \"DATA_DIMENSION_: %s\", data_dimension)\n",
        "  clf = GridSearchCV(fl.FuzzyInductor(), params, cv=stratified_folds(x, y, folds=folds)).fit(x, y)\n",
        "\n",
        "  log_info(logger, label, \"CV_RESULTS_: %s\", clf.cv_results_)\n",
        "  log_info(logger, label, \"BEST_SCORE_: %s\", clf.best_score_)\n",
        "  log_info(logger, label, \"BEST_PARAMS_: %s\", clf.best_params_)\n",
        "  return clf\n",
        "\n",
        "\n",
        "def nested_grid_search(x, y, params, data_dimension, data_reduction=\"t\", logger=None, y_needs_mapping=False, label=\"\", folds=3, innerFolds=3):\n",
        "  check_label(label)\n",
        "\n",
        "  log_info(logger, label, \"Started Nested-GridSearchCV with: %s\", params)\n",
        "  clf = grid_search(x, y, params, data_dimension, data_reduction=data_reduction, logger=logger, y_needs_mapping=y_needs_mapping, label=label, folds=innerFolds)\n",
        "\n",
        "  if(y_needs_mapping):\n",
        "    y = map_labels(y, label)\n",
        "\n",
        "  results = cross_val_score(clf.best_estimator_, x, y, cv=stratified_folds(x, y, folds=folds), verbose=10)\n",
        "\n",
        "  log_info(logger, label, \"NESTED CROSS VALIDATION with %s fold: %s\", folds, results)\n",
        "  log_info(logger, label, \"NESTED CROSS VALIDATION (mean): %s\", np.mean(results))\n",
        "\n",
        "def map_labels(y, label):\n",
        "    assert(label != \"\")\n",
        "    return [1 if elem == label else 0 for elem in y]\n",
        "\n",
        "def check_label(label):\n",
        "  assert(label != \"\" or label is not None) #is important to know which class is training \n",
        "\n",
        "def stratified_folds(X, y, random_state=0, folds=3):\n",
        "  return StratifiedShuffleSplit(n_splits=folds, random_state=random_state).split(X, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wW8kE3vKFLHr"
      },
      "source": [
        "# Plot utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UijhQp2KDJP_"
      },
      "outputs": [],
      "source": [
        "def show_scatter_plot(data, labels):\n",
        "  for lab in range(40):\n",
        "          plt.scatter(data[labels==lab, 0],\n",
        "                      data[labels==lab, 1],\n",
        "                      label=lab,\n",
        "                      c=[np.random.rand(3,)],\n",
        "                      marker=\"$\" + str(lab) + \"$\",\n",
        "                      s=200\n",
        "                      )\n",
        "  plt.show()\n",
        "\n",
        "def gr_membership_contour(estimated_membership, data, labels, label, with_label=False, precision=.25):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "  data_filtered = [list(elem) for elem, l in list(zip(data, labels)) if l == label]\n",
        "\n",
        "  offsetX = (maxX(data_filtered) - minX(data_filtered))/2\n",
        "  offsetY = (maxY(data_filtered) - minY(data_filtered))/2\n",
        "\n",
        "  x = np.arange(minX(data_filtered) - offsetX, maxX(data_filtered) + offsetX, precision)\n",
        "  y = np.arange(minY(data_filtered) - offsetY, maxY(data_filtered) + offsetY, precision)\n",
        "  X, Y = np.meshgrid(x, y)\n",
        "  zs = np.array([estimated_membership([[x, y]])\n",
        "                  for x,y in zip(np.ravel(X), np.ravel(Y))])\n",
        "  Z = zs.reshape(X.shape)\n",
        "\n",
        "  membership_contour = plt.contour(X, Y, Z,\n",
        "                                    levels=(.1, .3, .5, .7, .8, .9, .95), colors='k')\n",
        "  \n",
        "  if(with_label):\n",
        "    plt.clabel(membership_contour, inline=1)\n",
        "\n",
        "  plt.title(\"Membership contour on test {}\".format(label))\n",
        "  show_scatter_plot(data, labels)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def minX(x): return min(x, key=lambda t: t[0])[0]\n",
        "\n",
        "def maxX(x): return max(x, key=lambda t: t[0])[0]\n",
        "\n",
        "def minY(x): return min(x, key=lambda t: t[1])[1]\n",
        "\n",
        "def maxY(x): return max(x, key=lambda t: t[1])[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O4C4WrkDG-Rq"
      },
      "source": [
        "# Estimations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OfsmaWKgxGHz"
      },
      "outputs": [],
      "source": [
        "def build_best_model(data, labels, filename, c):\n",
        "  c_, fuzzifier_, (kernel_, param_) = get_params(logLines(filename), str(c))\n",
        "  return fl.FuzzyInductor(c=c_, fuzzifier=str2fuzzifier(fuzzifier_), k=str2kernel(kernel_)(param_)).fit(data, map_labels(labels, c))\n",
        "\n",
        "def get_models_on_best_params_holdout(data, labels, filename):\n",
        "  models = {}\n",
        "  for c in get_classes(labels):\n",
        "    c_, fuzzifier_, (kernel_, param_) = get_params(logLines(filename), str(c))\n",
        "    models[c] = fl.FuzzyInductor(c=c_, fuzzifier=str2fuzzifier(fuzzifier_), k=str2kernel(kernel_)(param_)).fit(data, map_labels(labels, c))\n",
        "\n",
        "  return models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-ydLHGhyLikK"
      },
      "outputs": [],
      "source": [
        "def get_correct_predictions(train_data, test_data, train_labels, test_labels, models, filename, logger=None):\n",
        "  predictions_test = []\n",
        "  predictions_train = []\n",
        "\n",
        "  for model in models:\n",
        "    predictions_test.append(models[model].predict(test_data))\n",
        "    predictions_train.append(models[model].predict(train_data))\n",
        "\n",
        "  zipped_predictions_test = list(zip(*predictions_test))\n",
        "  zipped_predictions_train = list(zip(*predictions_train))\n",
        "  results_test = list(zip([sorted(enumerate(predict), reverse=True, key=lambda x: x[1])[0][0] for predict in zipped_predictions_test], test_labels))\n",
        "  results_train = list(zip([sorted(enumerate(predict), reverse=True, key=lambda x: x[1])[0][0] for predict in zipped_predictions_train], train_labels))\n",
        "\n",
        "  res_test = sum([1 if elem[0] == elem[1] else 0 for elem in results_test])/len(test_labels)\n",
        "  res_train = sum([1 if elem[0] == elem[1] else 0 for elem in results_train])/len(train_labels)\n",
        "  diff_test = [elem for elem in results_test if elem[0] != elem[1]]\n",
        "  diff_train = [elem for elem in results_train if elem[0] != elem[1]]\n",
        "  \n",
        "  log_info(logger, None, \"CORRECT_TEST_PREDICTIONS_: %s\", res_test)\n",
        "  log_info(logger, None, \"CORRECT_TRAIN_PREDICTIONS_: %s\", res_train)\n",
        "  log_info(logger, None, \"DIFFERENT_TEST_RESULTS_: %s\", diff_test)\n",
        "  log_info(logger, None, \"DIFFERENT_TRAIN_RESULTS_: %s\", diff_train)\n",
        "\n",
        "  return (res_test, res_train, diff_test, diff_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KmODkD8tNr7Z"
      },
      "outputs": [],
      "source": [
        "logger = log_init(filename=ROOT + PROJ + \"/logs/of_results_predictions_tsne_2.log\")\n",
        "\n",
        "res_test, res_train, diff_test, diff_train = get_correct_predictions(get_tsne_data(olivetti_data), olivetti_labels, ROOT + PROJ + '/logs/of_tsne_2.log', logger=logger)\n",
        "res_test, res_train, diff_test, diff_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yh_pfmT0f_E3"
      },
      "source": [
        "# Model selection\n",
        "\n",
        "---\n",
        "\n",
        "Here you can find all of the training done with ``` grid_search ``` or ``` nested_grid_search ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NmlAtoUqWFuV"
      },
      "outputs": [],
      "source": [
        "def start_grid_search(data, labels, params, dimension, logger, filename):\n",
        "  lastAnalyzedClass_ = int(lastAnalyzedClass(logLines(filename)))\n",
        "\n",
        "  for c in get_classes(labels):\n",
        "    if(c > lastAnalyzedClass_):\n",
        "      grid_search(data, labels, params, dimension, data_reduction=\"p\", logger=logger, y_needs_mapping=True, label=c)\n",
        "\n",
        "def start_nested_grid_search(data, labels, params, dimension, logger, filename):\n",
        "  lastAnalyzedClass_ = int(lastAnalyzedClass(logLines(filename)))\n",
        "\n",
        "  for c in get_classes(labels):\n",
        "    if(c > lastAnalyzedClass_):\n",
        "      nested_grid_search(data, labels, params, dimension, data_reduction=\"p\", logger=logger, y_needs_mapping=True, label=c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WRE1w138cxbf"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'c': [1, 1000],\n",
        "    'k': [fl.kernel.GaussianKernel(sigma=.5), fl.kernel.GaussianKernel(sigma=.2)],\n",
        "    'fuzzifier': [fl.fuzzifiers.LinearFuzzifier, fl.fuzzifiers.QuantileLinearPiecewiseFuzzifier]\n",
        "}\n",
        "\n",
        "dimension = 2\n",
        "\n",
        "logger = log_init()\n",
        "\n",
        "start(params, dimension, logger)"
      ]
    }
  ]
}